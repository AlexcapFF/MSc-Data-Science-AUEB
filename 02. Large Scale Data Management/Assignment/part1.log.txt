papagandalf@cluster1-m:~$ hadoop jar hadoop-streaming-2.6.0.jar -file part1_mapper.py -mapper part1_mapper.py -file reducer.py -reducer reducer.py -input /data/shakespeare.txt -output /data/part_1_word_count
19/04/22 17:56:20 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
packageJobJar: [part1_mapper.py, reducer.py] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.9.2.jar] /tmp/streamjob6830182534578264014.jar tmpDir=null
19/04/22 17:56:21 INFO client.RMProxy: Connecting to ResourceManager at cluster1-m/10.132.0.14:8032
19/04/22 17:56:21 INFO client.AHSProxy: Connecting to Application History server at cluster1-m/10.132.0.14:10200
19/04/22 17:56:22 INFO client.RMProxy: Connecting to ResourceManager at cluster1-m/10.132.0.14:8032
19/04/22 17:56:22 INFO client.AHSProxy: Connecting to Application History server at cluster1-m/10.132.0.14:10200
19/04/22 17:56:22 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
        at java.lang.Object.wait(Native Method)
        at java.lang.Thread.join(Thread.java:1252)
        at java.lang.Thread.join(Thread.java:1326)
        at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:980)
        at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:630)
        at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:807)
19/04/22 17:56:22 INFO mapred.FileInputFormat: Total input files to process : 1
19/04/22 17:56:23 INFO mapreduce.JobSubmitter: number of splits:15
19/04/22 17:56:23 INFO Configuration.deprecation: yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
19/04/22 17:56:23 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1555953110757_0001
19/04/22 17:56:24 INFO impl.YarnClientImpl: Submitted application application_1555953110757_0001
19/04/22 17:56:24 INFO mapreduce.Job: The url to track the job: http://cluster1-m:8088/proxy/application_1555953110757_0001/
19/04/22 17:56:24 INFO mapreduce.Job: Running job: job_1555953110757_0001
19/04/22 17:56:34 INFO mapreduce.Job: Job job_1555953110757_0001 running in uber mode : false
19/04/22 17:56:34 INFO mapreduce.Job:  map 0% reduce 0%
19/04/22 17:56:44 INFO mapreduce.Job:  map 7% reduce 0%
19/04/22 17:56:45 INFO mapreduce.Job:  map 13% reduce 0%
19/04/22 17:56:48 INFO mapreduce.Job:  map 27% reduce 0%
19/04/22 17:56:49 INFO mapreduce.Job:  map 33% reduce 0%
19/04/22 17:56:53 INFO mapreduce.Job:  map 47% reduce 0%
19/04/22 17:57:01 INFO mapreduce.Job:  map 80% reduce 0%
19/04/22 17:57:06 INFO mapreduce.Job:  map 87% reduce 0%
19/04/22 17:57:09 INFO mapreduce.Job:  map 100% reduce 0%
19/04/22 17:57:19 INFO mapreduce.Job:  map 100% reduce 20%
19/04/22 17:57:20 INFO mapreduce.Job:  map 100% reduce 40%
19/04/22 17:57:22 INFO mapreduce.Job:  map 100% reduce 60%
19/04/22 17:57:25 INFO mapreduce.Job:  map 100% reduce 80%
19/04/22 17:57:26 INFO mapreduce.Job:  map 100% reduce 100%
19/04/22 17:57:26 INFO mapreduce.Job: Job job_1555953110757_0001 completed successfully
19/04/22 17:57:27 INFO mapreduce.Job: Counters: 51
        File System Counters
                FILE: Number of bytes read=17154753
                FILE: Number of bytes written=38525316
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=5648583
                HDFS: Number of bytes written=5976049
                HDFS: Number of read operations=70
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=15
        Job Counters 
                Killed map tasks=1
                Killed reduce tasks=1
                Launched map tasks=15
                Launched reduce tasks=5
                Data-local map tasks=15
                Total time spent by all maps in occupied slots (ms)=543664
                Total time spent by all reduces in occupied slots (ms)=200468
                Total time spent by all map tasks (ms)=135916
                Total time spent by all reduce tasks (ms)=50117
                Total vcore-milliseconds taken by all map tasks=135916
                Total vcore-milliseconds taken by all reduce tasks=50117
                Total megabyte-milliseconds taken by all map tasks=278355968
                Total megabyte-milliseconds taken by all reduce tasks=102639616
        Map-Reduce Framework
                Map input records=124787
                Map output records=817247
                Map output bytes=15520229
                Map output materialized bytes=17155173
                Input split bytes=1350
                Combine input records=0
                Combine output records=0
                Reduce input groups=288521
                Reduce shuffle bytes=17155173
                Reduce input records=817247
                Reduce output records=288521
                Spilled Records=1634494
                Shuffled Maps =75
                Failed Shuffles=0
                Merged Map outputs=75
                GC time elapsed (ms)=4912
                CPU time spent (ms)=40420
                Physical memory (bytes) snapshot=8696152064
                Virtual memory (bytes) snapshot=70107455488
                Total committed heap usage (bytes)=7723286528
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters 
                Bytes Read=5647233
        File Output Format Counters 
                Bytes Written=5976049
19/04/22 17:57:27 INFO streaming.StreamJob: Output directory: /data/part_1_word_count
