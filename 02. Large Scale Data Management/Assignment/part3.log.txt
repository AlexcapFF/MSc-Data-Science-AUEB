papagandalf@cluster1-m:~$ hadoop jar hadoop-streaming-2.6.0.jar -file part3_mapper.py -mapper part3_mapper.py -file reducer.py -reducer reducer.py -input /data/shakespeare.txt -output /data/part_3_word_count  
19/04/22 18:05:45 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
packageJobJar: [part3_mapper.py, reducer.py] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.9.2.jar] /tmp/streamjob5043184096292289479.jar tmpDir=null
19/04/22 18:05:46 INFO client.RMProxy: Connecting to ResourceManager at cluster1-m/10.132.0.14:8032
19/04/22 18:05:46 INFO client.AHSProxy: Connecting to Application History server at cluster1-m/10.132.0.14:10200
19/04/22 18:05:47 INFO client.RMProxy: Connecting to ResourceManager at cluster1-m/10.132.0.14:8032
19/04/22 18:05:47 INFO client.AHSProxy: Connecting to Application History server at cluster1-m/10.132.0.14:10200
19/04/22 18:05:47 INFO mapred.FileInputFormat: Total input files to process : 1
19/04/22 18:05:47 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
        at java.lang.Object.wait(Native Method)
        at java.lang.Thread.join(Thread.java:1252)
        at java.lang.Thread.join(Thread.java:1326)
        at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:980)
        at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:630)
        at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:807)
19/04/22 18:05:47 INFO mapreduce.JobSubmitter: number of splits:15
19/04/22 18:05:48 INFO Configuration.deprecation: yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
19/04/22 18:05:48 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1555953110757_0002
19/04/22 18:05:48 INFO impl.YarnClientImpl: Submitted application application_1555953110757_0002
19/04/22 18:05:48 INFO mapreduce.Job: The url to track the job: http://cluster1-m:8088/proxy/application_1555953110757_0002/
19/04/22 18:05:48 INFO mapreduce.Job: Running job: job_1555953110757_0002
19/04/22 18:05:55 INFO mapreduce.Job: Job job_1555953110757_0002 running in uber mode : false
19/04/22 18:05:55 INFO mapreduce.Job:  map 0% reduce 0%
19/04/22 18:06:08 INFO mapreduce.Job:  map 13% reduce 0%
19/04/22 18:06:11 INFO mapreduce.Job:  map 33% reduce 0%
19/04/22 18:06:19 INFO mapreduce.Job:  map 47% reduce 0%
19/04/22 18:06:26 INFO mapreduce.Job:  map 60% reduce 0%
19/04/22 18:06:27 INFO mapreduce.Job:  map 67% reduce 0%
19/04/22 18:06:30 INFO mapreduce.Job:  map 80% reduce 0%
19/04/22 18:06:41 INFO mapreduce.Job:  map 87% reduce 0%
19/04/22 18:06:42 INFO mapreduce.Job:  map 93% reduce 0%
19/04/22 18:06:43 INFO mapreduce.Job:  map 100% reduce 0%
19/04/22 18:06:59 INFO mapreduce.Job:  map 100% reduce 20%
19/04/22 18:07:00 INFO mapreduce.Job:  map 100% reduce 40%
19/04/22 18:07:02 INFO mapreduce.Job:  map 100% reduce 58%
19/04/22 18:07:05 INFO mapreduce.Job:  map 100% reduce 78%
19/04/22 18:07:06 INFO mapreduce.Job:  map 100% reduce 80%
19/04/22 18:07:07 INFO mapreduce.Job:  map 100% reduce 99%
19/04/22 18:07:08 INFO mapreduce.Job:  map 100% reduce 100%
19/04/22 18:07:09 INFO mapreduce.Job: Job job_1555953110757_0002 completed successfully
19/04/22 18:07:09 INFO mapreduce.Job: Counters: 51
        File System Counters
                FILE: Number of bytes read=157525056
                FILE: Number of bytes written=319265922
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=5648583
                HDFS: Number of bytes written=41700574
                HDFS: Number of read operations=70
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=15
        Job Counters 
                Killed map tasks=1
                Killed reduce tasks=1
                Launched map tasks=15
                Launched reduce tasks=6
                Data-local map tasks=15
                Total time spent by all maps in occupied slots (ms)=748588
                Total time spent by all reduces in occupied slots (ms)=399356
                Total time spent by all map tasks (ms)=187147
                Total time spent by all reduce tasks (ms)=99839
                Total vcore-milliseconds taken by all map tasks=187147
                Total vcore-milliseconds taken by all reduce tasks=99839
                Total megabyte-milliseconds taken by all map tasks=383277056
                Total megabyte-milliseconds taken by all reduce tasks=204470272
        Map-Reduce Framework
                Map input records=124787
                Map output records=7516042
                Map output bytes=142492942
                Map output materialized bytes=157525476
                Input split bytes=1350
                Combine input records=0
                Combine output records=0
                Reduce input groups=1955428
                Reduce shuffle bytes=157525476
                Reduce input records=7516042
                Reduce output records=1955428
                Spilled Records=15032084
                Shuffled Maps =75
                Failed Shuffles=0
                Merged Map outputs=75
                GC time elapsed (ms)=4814
                CPU time spent (ms)=86290
                Physical memory (bytes) snapshot=8847216640
                Virtual memory (bytes) snapshot=70103724032
                Total committed heap usage (bytes)=7974944768
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters 
                Bytes Read=5647233
        File Output Format Counters 
                Bytes Written=41700574
19/04/22 18:07:09 INFO streaming.StreamJob: Output directory: /data/part_3_word_count
